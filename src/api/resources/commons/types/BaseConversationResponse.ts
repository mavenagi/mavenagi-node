// This file was auto-generated by Fern from our API Definition.

import * as MavenAGI from "../../../index";

export interface BaseConversationResponse {
    /** Optional configurations for responses to this conversation */
    responseConfig?: MavenAGI.ResponseConfig;
    /** The subject of the conversation */
    subject?: string;
    /** The url of the conversation */
    url?: string;
    /** The date and time the conversation was created */
    createdAt?: Date;
    /** The date and time the conversation was last updated */
    updatedAt?: Date;
    /** The tags of the conversation. Used for filtering in Agent Designer. */
    tags?: Set<string>;
    /** The metadata of the conversation supplied by the app which created the conversation. */
    metadata?: Record<string, string>;
    /** All metadata for the conversation. Keyed by appId. */
    allMetadata: Record<string, Record<string, string>>;
    /** The ID that uniquely identifies this conversation */
    conversationId: MavenAGI.EntityId;
    /** An analysis of the conversation. Fields are generated by Maven via an analysis of user messages. This object is calculated on a delay. Fields will not be up to date on ask requests. */
    analysis: MavenAGI.ConversationAnalysis;
    /** A summary of the conversation. Fields are calculated from conversation data. Unlike analysis, all fields can be derived from other data available in the API. This object is provided as a convenience and is calculated on a delay. Fields will not be up to date on ask requests. */
    summary: MavenAGI.ConversationSummary;
    /** Whether the conversation user-specific data has been deleted. See `deleteConversation` for details. */
    deleted: boolean;
    /**
     * Whether the conversation is able to receive asynchronous messages.
     * Only applicable if a conversation is initialized with the `ASYNC` capability. Defaults to true. Can be closed using the `PATCH` API.
     */
    open: boolean;
    /**
     * Whether the LLM is enabled for this conversation.
     * If true, `USER` messages sent via the ask API will be sent to the LLM and a `BOT_RESPONSE` or `BOT_SUGGESTION` message will be generated.
     * If false, `USER` messages will not be sent to the LLM.
     */
    llmEnabled: boolean;
    /**
     * Additional context used for simulation runs. When present, this conversation is treated as a simulation.
     * Simulation conversations are excluded from normal search results unless explicitly included via the `simulationFilter` field.
     */
    simulationContext?: MavenAGI.SimulationContext;
}
